{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the general settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOMSTATE = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'peregrine/t5_t5base/models/pytorch_model_semtag_base_split.bin'\n",
    "ORIGINAL_MODEL = 't5-base'\n",
    "CONFIG = 'configs/t5_base-config.json'\n",
    "PREFIX = 'semtag'\n",
    "CSV_LOC = 'peregrine/t5_t5base'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Partially based on https://github.com/MathewAlexander/T5_nlg'''\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, set_seed\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOMSTATE)\n",
    "set_seed(RANDOMSTATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup functions for generation and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_checker():\n",
    "    '''Checking for the GPU availability.'''\n",
    "    if torch.cuda.is_available():\n",
    "        dev = torch.device(\"cuda:0\")\n",
    "        print(\"Running on the GPU\")\n",
    "    else:\n",
    "        dev = torch.device(\"cpu\")\n",
    "        print(\"Running on the CPU\")\n",
    "\n",
    "    return dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(text):\n",
    "    '''Generates a sentence given a specific\n",
    "    pytorch_model.bin and returns it.\n",
    "    '''\n",
    "    extra_tokens = ['~', 'ø']\n",
    "    # model = T5ForConditionalGeneration.from_pretrained('pytorch_model.bin', return_dict=True, config='t5-small-config.json')\n",
    "    dev = gpu_checker()\n",
    "    model = T5ForConditionalGeneration.from_pretrained(MODEL, return_dict=True, config=CONFIG)\n",
    "    model.to(dev)\n",
    "    \n",
    "    tokenizer = T5Tokenizer.from_pretrained(ORIGINAL_MODEL, model_max_length=512)\n",
    "\n",
    "    new_tokens = tokenizer.additional_special_tokens + extra_tokens\n",
    "    tokenizer = T5Tokenizer.from_pretrained(ORIGINAL_MODEL, additional_special_tokens=new_tokens, model_max_length=512)\n",
    "    # print('\\nSpecial tokens: ', tokenizer.get_added_vocab())\n",
    "\n",
    "    input_ids = tokenizer.encode(\"{}: {}\".format(PREFIX, text), return_tensors=\"pt\").to(dev)  # Batch size 1\n",
    "    outputs = model.generate(input_ids, num_beams=10, max_length=500).to(dev)\n",
    "    gen_text = tokenizer.decode(outputs[0]).replace('<pad>','').replace('</s>','')\n",
    "\n",
    "    return gen_text.lstrip().rstrip().replace(' ~ ', '~').replace(' ø ', 'ø')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_item_checker(cur_output: str, cur_input_token_list: list, cur_input_tag_list: list):\n",
    "    '''Checks for missing items using multiple conditions and adds them as MISSING to the tags.'''\n",
    "    if ';;' in cur_output:\n",
    "        cur_output.replace(';;', '\";\" ;')\n",
    "    elif '; ;' in cur_output:\n",
    "        cur_output.replace('; ;', '\";\" ;')\n",
    "\n",
    "    output_list = cur_output.split(';')\n",
    "\n",
    "    output_list_tag = []\n",
    "    output_list_token = []\n",
    "    cntr = -1\n",
    "\n",
    "    for item in output_list:\n",
    "        cntr += 1\n",
    "        if ':' in item:\n",
    "            tag, token = item.split(':', 1)\n",
    "               \n",
    "            if '\";\"' in token:\n",
    "                token.replace('\";\"', ';')\n",
    "            output_list_tag.append(tag.lstrip().rstrip())\n",
    "            output_list_token.append(token.lstrip().rstrip())\n",
    "        else:\n",
    "            if '\";\"' in token:\n",
    "                token.replace('\";\"', ';')\n",
    "            if item.lstrip().rstrip() in cur_input_token_list:\n",
    "                output_list_tag.append('MISSING')\n",
    "                output_list_token.append(item.lstrip().rstrip())\n",
    "            elif item.lstrip().rstrip() in cur_input_tag_list:\n",
    "                output_list_tag.append(item.lstrip().rstrip())\n",
    "                output_list_token.append(cur_input_token_list[cntr])\n",
    "            else:\n",
    "                output_list_tag.append('MISSING')\n",
    "                output_list_token.append('MISSING')\n",
    "                \n",
    "    cntr = -1\n",
    "    if len(cur_input_token_list) != len(output_list_tag):\n",
    "        # print('The amount of items is not the same, starting missing item operation.')\n",
    "        # for token in tqdm(cur_input_token_list, desc='Looking for missing items'):\n",
    "        for token in cur_input_token_list:\n",
    "            cntr += 1\n",
    "            if token not in output_list_token:\n",
    "                output_list_tag.insert(cntr, 'MISSING')\n",
    "\n",
    "    return output_list_token, output_list_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(df: pd.DataFrame):\n",
    "    '''Generates the t5 output for each row in a given dataframe.'''\n",
    "    df_output_strings = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=df.shape[0], desc='Generating T5 output for each row'):\n",
    "\n",
    "        input_token_list = row['token']\n",
    "        input_tag_list = row['semtag']\n",
    "        input_token_str = ' '.join(input_token_list)\n",
    "        cur_generation = generate(input_token_str)\n",
    "        df_output_strings.append(cur_generation)\n",
    "\n",
    "    df['generated_strings'] = df_output_strings\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taglen(df: pd.DataFrame, df_col):\n",
    "    '''Returns the length for the given column in each row of a dataframe.'''\n",
    "    len_list = [len(row[df_col]) for idx, row in df.iterrows()]\n",
    "    return sum(len_list), len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_importer():\n",
    "    '''Imports the train and test dataframes from the csv data.'''\n",
    "    df = pd.read_csv('../Data/sem-pmb_4_0_0-gold.csv')\n",
    "\n",
    "    grouped_sentences = df.groupby('sent_file').agg({'token': list, 'lemma': list, 'from': list, 'to': list, 'semtag': list}).reset_index()\n",
    "\n",
    "    output_sentences = []\n",
    "    for index, data in grouped_sentences.iterrows():\n",
    "        current_sentence = []\n",
    "        for word in data[1]:\n",
    "            current_sentence.append('{}: '.format(data[-1][data[1].index(word)]))\n",
    "\n",
    "            current_sentence.append(word)\n",
    "            if word != data[1][-1]:\n",
    "                current_sentence.append('; ')\n",
    "\n",
    "        output_sentences.append(current_sentence)\n",
    "\n",
    "    grouped_sentences['output'] = output_sentences\n",
    "       \n",
    "    df_train, df_test = train_test_split(grouped_sentences, test_size=0.2, random_state=RANDOMSTATE)\n",
    "    \n",
    "    return df_train, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = test_importer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problematic output example index 14: 'DEF:ø; PER: Yunus ; EPS: founded ; DEF: the ; ORG: Grameen~Bank ; DIS:ø; 30 ; UOM: years ; PST: ago ; NIL:.'\n",
    "\n",
    "30 has no tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = batch_generator(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'test_outputs/{ORIGINAL_MODEL}'\n",
    "Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "now = datetime.now()\n",
    "timestring = now.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "output_name = f'{output_path}/{timestring}-test_output_{ORIGINAL_MODEL}'\n",
    "\n",
    "df_test.to_json(f'{output_name}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_json(f'{output_name}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(columns=['from', 'to', 'lemma'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_file</th>\n",
       "      <th>token</th>\n",
       "      <th>semtag</th>\n",
       "      <th>output</th>\n",
       "      <th>generated_strings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10136</th>\n",
       "      <td>pmb-4.0.0/data/en/gold/p94/d1295/en.drs.xml</td>\n",
       "      <td>[On, ø, October, 2, ,, 1942, ,, he, was, at, t...</td>\n",
       "      <td>[REL, DIS, MOY, DOM, EQU, YOC, NIL, PRO, EPS, ...</td>\n",
       "      <td>[REL: , On, ; , DIS: , ø, ; , MOY: , October, ...</td>\n",
       "      <td>REL: On ; DEF:ø; MOY: October ; DOM: 2 ; NIL:,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>pmb-4.0.0/data/en/gold/p14/d1574/en.drs.xml</td>\n",
       "      <td>[What, kind, of, ø, American, accent, does, ø,...</td>\n",
       "      <td>[QUE, CON, REL, DIS, GPO, CON, NOW, DEF, PER, ...</td>\n",
       "      <td>[QUE: , What, ; , CON: , kind, ; , REL: , of, ...</td>\n",
       "      <td>QUE: What ; CON: kind ; REL: of ; DIS:ø; GPO: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9570</th>\n",
       "      <td>pmb-4.0.0/data/en/gold/p88/d1269/en.drs.xml</td>\n",
       "      <td>[The, two, truck~drivers, were, arrested, .]</td>\n",
       "      <td>[DEF, QUC, ROL, PST, EXS, NIL]</td>\n",
       "      <td>[DEF: , The, ; , QUC: , two, ; , ROL: , truck~...</td>\n",
       "      <td>DEF: The ; QUC: two ; ROL: truck~drivers ; PST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5608</th>\n",
       "      <td>pmb-4.0.0/data/en/gold/p42/d0760/en.drs.xml</td>\n",
       "      <td>[ø, Hooper, bought, a, house, in, ø, Portland, .]</td>\n",
       "      <td>[DEF, PER, EPS, DIS, CON, REL, DEF, GPE, NIL]</td>\n",
       "      <td>[DEF: , ø, ; , PER: , Hooper, ; , EPS: , bough...</td>\n",
       "      <td>DEF:ø; PER: Hooper ; EPS: bought ; DIS: a ; CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9455</th>\n",
       "      <td>pmb-4.0.0/data/en/gold/p86/d2746/en.drs.xml</td>\n",
       "      <td>[We, went, fishing, in, the, lake, .]</td>\n",
       "      <td>[PRO, PST, EXG, REL, DEF, CON, NIL]</td>\n",
       "      <td>[PRO: , We, ; , PST: , went, ; , EXG: , fishin...</td>\n",
       "      <td>PRO: We ; PST: went ; EXG: fishing ; REL: in ;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sent_file  \\\n",
       "10136  pmb-4.0.0/data/en/gold/p94/d1295/en.drs.xml   \n",
       "2673   pmb-4.0.0/data/en/gold/p14/d1574/en.drs.xml   \n",
       "9570   pmb-4.0.0/data/en/gold/p88/d1269/en.drs.xml   \n",
       "5608   pmb-4.0.0/data/en/gold/p42/d0760/en.drs.xml   \n",
       "9455   pmb-4.0.0/data/en/gold/p86/d2746/en.drs.xml   \n",
       "\n",
       "                                                   token  \\\n",
       "10136  [On, ø, October, 2, ,, 1942, ,, he, was, at, t...   \n",
       "2673   [What, kind, of, ø, American, accent, does, ø,...   \n",
       "9570        [The, two, truck~drivers, were, arrested, .]   \n",
       "5608   [ø, Hooper, bought, a, house, in, ø, Portland, .]   \n",
       "9455               [We, went, fishing, in, the, lake, .]   \n",
       "\n",
       "                                                  semtag  \\\n",
       "10136  [REL, DIS, MOY, DOM, EQU, YOC, NIL, PRO, EPS, ...   \n",
       "2673   [QUE, CON, REL, DIS, GPO, CON, NOW, DEF, PER, ...   \n",
       "9570                      [DEF, QUC, ROL, PST, EXS, NIL]   \n",
       "5608       [DEF, PER, EPS, DIS, CON, REL, DEF, GPE, NIL]   \n",
       "9455                 [PRO, PST, EXG, REL, DEF, CON, NIL]   \n",
       "\n",
       "                                                  output  \\\n",
       "10136  [REL: , On, ; , DIS: , ø, ; , MOY: , October, ...   \n",
       "2673   [QUE: , What, ; , CON: , kind, ; , REL: , of, ...   \n",
       "9570   [DEF: , The, ; , QUC: , two, ; , ROL: , truck~...   \n",
       "5608   [DEF: , ø, ; , PER: , Hooper, ; , EPS: , bough...   \n",
       "9455   [PRO: , We, ; , PST: , went, ; , EXG: , fishin...   \n",
       "\n",
       "                                       generated_strings  \n",
       "10136  REL: On ; DEF:ø; MOY: October ; DOM: 2 ; NIL:,...  \n",
       "2673   QUE: What ; CON: kind ; REL: of ; DIS:ø; GPO: ...  \n",
       "9570   DEF: The ; QUC: two ; ROL: truck~drivers ; PST...  \n",
       "5608   DEF:ø; PER: Hooper ; EPS: bought ; DIS: a ; CO...  \n",
       "9455   PRO: We ; PST: went ; EXG: fishing ; REL: in ;...  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEF:ø; CTC: http://www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.www.'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.iloc[115].generated_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2143/2143 [00:00<00:00, 24365.46it/s]\n"
     ]
    }
   ],
   "source": [
    "output_list_token_list = []\n",
    "output_list_tag_list = []\n",
    "\n",
    "for idx, row in tqdm(df_test.iterrows(), total=df_test.shape[0]):\n",
    "    output_list_token = []\n",
    "    output_list_tag = []\n",
    "\n",
    "    output_list_token, output_list_tag = missing_item_checker(row['generated_strings'], row['token'], row['semtag'])\n",
    "    \n",
    "    output_list_token_list.append(output_list_token)\n",
    "    output_list_tag_list.append(output_list_tag)\n",
    "\n",
    "df_test['generated_tokens'] = output_list_token_list\n",
    "df_test['generated_tags'] = output_list_tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_file</th>\n",
       "      <th>token</th>\n",
       "      <th>semtag</th>\n",
       "      <th>output</th>\n",
       "      <th>generated_strings</th>\n",
       "      <th>generated_tokens</th>\n",
       "      <th>generated_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10136</th>\n",
       "      <td>pmb-4.0.0/data/en/gold/p94/d1295/en.drs.xml</td>\n",
       "      <td>[On, ø, October, 2, ,, 1942, ,, he, was, at, t...</td>\n",
       "      <td>[REL, DIS, MOY, DOM, EQU, YOC, NIL, PRO, EPS, ...</td>\n",
       "      <td>[REL: , On, ; , DIS: , ø, ; , MOY: , October, ...</td>\n",
       "      <td>REL: On ; DEF:ø; MOY: October ; DOM: 2 ; NIL:,...</td>\n",
       "      <td>[On, ø, October, 2, ,, 1942, ,, he, was, at, t...</td>\n",
       "      <td>[REL, DEF, MOY, DOM, NIL, YOC, NIL, PRO, EPS, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>pmb-4.0.0/data/en/gold/p14/d1574/en.drs.xml</td>\n",
       "      <td>[What, kind, of, ø, American, accent, does, ø,...</td>\n",
       "      <td>[QUE, CON, REL, DIS, GPO, CON, NOW, DEF, PER, ...</td>\n",
       "      <td>[QUE: , What, ; , CON: , kind, ; , REL: , of, ...</td>\n",
       "      <td>QUE: What ; CON: kind ; REL: of ; DIS:ø; GPO: ...</td>\n",
       "      <td>[What, kind, of, ø, American, accent, does, ø,...</td>\n",
       "      <td>[QUE, CON, REL, DIS, GPO, CON, NOW, DEF, PER, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9570</th>\n",
       "      <td>pmb-4.0.0/data/en/gold/p88/d1269/en.drs.xml</td>\n",
       "      <td>[The, two, truck~drivers, were, arrested, .]</td>\n",
       "      <td>[DEF, QUC, ROL, PST, EXS, NIL]</td>\n",
       "      <td>[DEF: , The, ; , QUC: , two, ; , ROL: , truck~...</td>\n",
       "      <td>DEF: The ; QUC: two ; ROL: truck~drivers ; PST...</td>\n",
       "      <td>[The, two, truck~drivers, were, arrested, .]</td>\n",
       "      <td>[DEF, QUC, ROL, PST, EXS, NIL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5608</th>\n",
       "      <td>pmb-4.0.0/data/en/gold/p42/d0760/en.drs.xml</td>\n",
       "      <td>[ø, Hooper, bought, a, house, in, ø, Portland, .]</td>\n",
       "      <td>[DEF, PER, EPS, DIS, CON, REL, DEF, GPE, NIL]</td>\n",
       "      <td>[DEF: , ø, ; , PER: , Hooper, ; , EPS: , bough...</td>\n",
       "      <td>DEF:ø; PER: Hooper ; EPS: bought ; DIS: a ; CO...</td>\n",
       "      <td>[ø, Hooper, bought, a, house, in, ø, Portland, .]</td>\n",
       "      <td>[DEF, PER, EPS, DIS, CON, REL, DEF, GPE, NIL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9455</th>\n",
       "      <td>pmb-4.0.0/data/en/gold/p86/d2746/en.drs.xml</td>\n",
       "      <td>[We, went, fishing, in, the, lake, .]</td>\n",
       "      <td>[PRO, PST, EXG, REL, DEF, CON, NIL]</td>\n",
       "      <td>[PRO: , We, ; , PST: , went, ; , EXG: , fishin...</td>\n",
       "      <td>PRO: We ; PST: went ; EXG: fishing ; REL: in ;...</td>\n",
       "      <td>[We, went, fishing, in, the, lake, .]</td>\n",
       "      <td>[PRO, PST, EXG, REL, DEF, CON, NIL]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sent_file  \\\n",
       "10136  pmb-4.0.0/data/en/gold/p94/d1295/en.drs.xml   \n",
       "2673   pmb-4.0.0/data/en/gold/p14/d1574/en.drs.xml   \n",
       "9570   pmb-4.0.0/data/en/gold/p88/d1269/en.drs.xml   \n",
       "5608   pmb-4.0.0/data/en/gold/p42/d0760/en.drs.xml   \n",
       "9455   pmb-4.0.0/data/en/gold/p86/d2746/en.drs.xml   \n",
       "\n",
       "                                                   token  \\\n",
       "10136  [On, ø, October, 2, ,, 1942, ,, he, was, at, t...   \n",
       "2673   [What, kind, of, ø, American, accent, does, ø,...   \n",
       "9570        [The, two, truck~drivers, were, arrested, .]   \n",
       "5608   [ø, Hooper, bought, a, house, in, ø, Portland, .]   \n",
       "9455               [We, went, fishing, in, the, lake, .]   \n",
       "\n",
       "                                                  semtag  \\\n",
       "10136  [REL, DIS, MOY, DOM, EQU, YOC, NIL, PRO, EPS, ...   \n",
       "2673   [QUE, CON, REL, DIS, GPO, CON, NOW, DEF, PER, ...   \n",
       "9570                      [DEF, QUC, ROL, PST, EXS, NIL]   \n",
       "5608       [DEF, PER, EPS, DIS, CON, REL, DEF, GPE, NIL]   \n",
       "9455                 [PRO, PST, EXG, REL, DEF, CON, NIL]   \n",
       "\n",
       "                                                  output  \\\n",
       "10136  [REL: , On, ; , DIS: , ø, ; , MOY: , October, ...   \n",
       "2673   [QUE: , What, ; , CON: , kind, ; , REL: , of, ...   \n",
       "9570   [DEF: , The, ; , QUC: , two, ; , ROL: , truck~...   \n",
       "5608   [DEF: , ø, ; , PER: , Hooper, ; , EPS: , bough...   \n",
       "9455   [PRO: , We, ; , PST: , went, ; , EXG: , fishin...   \n",
       "\n",
       "                                       generated_strings  \\\n",
       "10136  REL: On ; DEF:ø; MOY: October ; DOM: 2 ; NIL:,...   \n",
       "2673   QUE: What ; CON: kind ; REL: of ; DIS:ø; GPO: ...   \n",
       "9570   DEF: The ; QUC: two ; ROL: truck~drivers ; PST...   \n",
       "5608   DEF:ø; PER: Hooper ; EPS: bought ; DIS: a ; CO...   \n",
       "9455   PRO: We ; PST: went ; EXG: fishing ; REL: in ;...   \n",
       "\n",
       "                                        generated_tokens  \\\n",
       "10136  [On, ø, October, 2, ,, 1942, ,, he, was, at, t...   \n",
       "2673   [What, kind, of, ø, American, accent, does, ø,...   \n",
       "9570        [The, two, truck~drivers, were, arrested, .]   \n",
       "5608   [ø, Hooper, bought, a, house, in, ø, Portland, .]   \n",
       "9455               [We, went, fishing, in, the, lake, .]   \n",
       "\n",
       "                                          generated_tags  \n",
       "10136  [REL, DEF, MOY, DOM, NIL, YOC, NIL, PRO, EPS, ...  \n",
       "2673   [QUE, CON, REL, DIS, GPO, CON, NOW, DEF, PER, ...  \n",
       "9570                      [DEF, QUC, ROL, PST, EXS, NIL]  \n",
       "5608       [DEF, PER, EPS, DIS, CON, REL, DEF, GPE, NIL]  \n",
       "9455                 [PRO, PST, EXG, REL, DEF, CON, NIL]  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_total_tokens: 15751\n",
      "gold_total_tokens: 15470\n"
     ]
    }
   ],
   "source": [
    "df_pred_len, df_pred_len_list = taglen(df_test, 'generated_tags')\n",
    "df_gold_len, df_gold_len_list = taglen(df_test, 'semtag')\n",
    "\n",
    "print(f'prediction_total_tokens: {df_pred_len}')\n",
    "print(f'gold_total_tokens: {df_gold_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2143 2143\n"
     ]
    }
   ],
   "source": [
    "print(len(df_pred_len_list), len(df_gold_len_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following sentence indices differ: 46, 91, 105, 170, 235, 256, 349, 482, 483, 497, 516, 517, 572, 584, 715, 726, 760, 807, 814, 896, 900, 923, 937, 1036, 1063, 1122, 1145, 1232, 1270, 1302, 1454, 1579, 1611, 1624, 1675, 1682, 1699, 1703, 1806, 1861, 1982, 2057, 2090, 2107, 2125, 2136\n"
     ]
    }
   ],
   "source": [
    "if df_pred_len != df_gold_len:\n",
    "    dis = [i for i in range(len(df_gold_len_list)) if df_pred_len_list[i] != df_gold_len_list[i]]\n",
    "    # dis = []\n",
    "    # for i in range(len(df_gold_len_list)):\n",
    "    #     if df_pred_len_list[i] != df_gold_len_list[i]:\n",
    "    #         dis.append(i)\n",
    "        \n",
    "print('The following sentence indices differ: {}'.format(', '.join(map(str, dis))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparer(idx):\n",
    "    print('ID: {}\\nGold({}): {}\\nPred({}): {}\\n'.format(idx, len(df_test.iloc[idx].semtag), df_test.iloc[idx].semtag, len(df_test.iloc[idx].generated_tags), df_test.iloc[idx].generated_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tags = df_test.generated_tags.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dis:\n",
    "    del pred_tags[i][len(df_test.iloc[i].semtag):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['generated_tags'] = pred_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_total_tokens: 15464\n",
      "gold_total_tokens: 15470\n"
     ]
    }
   ],
   "source": [
    "df_pred_len, df_pred_len_list = taglen(df_test, 'generated_tags')\n",
    "df_gold_len, df_gold_len_list = taglen(df_test, 'semtag')\n",
    "\n",
    "print(f'prediction_total_tokens: {df_pred_len}')\n",
    "print(f'gold_total_tokens: {df_gold_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following sentence indices differ: 349, 497, 937, 1302, 1699, 1861\n"
     ]
    }
   ],
   "source": [
    "if df_pred_len != df_gold_len:\n",
    "    dis = [i for i in range(len(df_gold_len_list)) if df_pred_len_list[i] != df_gold_len_list[i]]\n",
    "    # dis = []\n",
    "    # for i in range(len(df_gold_len_list)):\n",
    "    #     if df_pred_len_list[i] != df_gold_len_list[i]:\n",
    "    #         dis.append(i)\n",
    "        \n",
    "print('The following sentence indices differ: {}'.format(', '.join(map(str, dis))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dis[::-1]:\n",
    "    df_test.drop(df_test.iloc[i].name, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_total_tokens: 15388\n",
      "gold_total_tokens: 15388\n"
     ]
    }
   ],
   "source": [
    "df_pred_len, df_pred_len_list = taglen(df_test, 'generated_tags')\n",
    "df_gold_len, df_gold_len_list = taglen(df_test, 'semtag')\n",
    "\n",
    "print(f'prediction_total_tokens: {df_pred_len}')\n",
    "print(f'gold_total_tokens: {df_gold_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following sentence indices differ: 349, 497, 937, 1302, 1699, 1861\n"
     ]
    }
   ],
   "source": [
    "if df_pred_len != df_gold_len:\n",
    "    dis = [i for i in range(len(df_gold_len_list)) if df_pred_len_list[i] != df_gold_len_list[i]]\n",
    "    # dis = []\n",
    "    # for i in range(len(df_gold_len_list)):\n",
    "    #     if df_pred_len_list[i] != df_gold_len_list[i]:\n",
    "    #         dis.append(i)\n",
    "        \n",
    "print('The following sentence indices differ: {}'.format(', '.join(map(str, dis))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALT       0.98      0.89      0.93        47\n",
      "         AND       0.96      0.74      0.84       104\n",
      "         APX       0.94      0.89      0.91        18\n",
      "         ART       0.36      0.45      0.40        11\n",
      "         BOT       1.00      1.00      1.00         2\n",
      "         BUT       1.00      0.89      0.94        19\n",
      "         CLO       1.00      0.90      0.95        39\n",
      "         COL       0.89      0.93      0.91        27\n",
      "         CON       0.97      0.98      0.98      1760\n",
      "         COO       0.81      0.85      0.83        26\n",
      "         CTC       1.00      1.00      1.00         4\n",
      "         DEF       0.93      0.96      0.94      1597\n",
      "         DEG       0.75      0.90      0.82        60\n",
      "         DIS       0.90      0.87      0.89       980\n",
      "         DOM       1.00      0.70      0.82        10\n",
      "         DOW       1.00      1.00      1.00         5\n",
      "         DST       0.96      0.96      0.96        51\n",
      "         EFS       0.62      0.62      0.62         8\n",
      "         EMP       0.97      0.95      0.96        77\n",
      "         ENS       0.95      0.97      0.96       469\n",
      "         EPS       0.99      0.98      0.99       738\n",
      "         EQU       0.50      0.70      0.58        23\n",
      "         EXG       0.96      0.99      0.98       221\n",
      "         EXS       0.96      0.95      0.95       368\n",
      "         EXT       0.95      0.92      0.93        59\n",
      "         FUT       0.98      0.94      0.96        65\n",
      "         GEO       0.94      0.62      0.74        26\n",
      "         GPE       0.90      0.90      0.90       135\n",
      "         GPO       0.92      0.97      0.95        36\n",
      "         GRE       1.00      1.00      1.00         1\n",
      "         GRP       0.88      0.92      0.90        25\n",
      "         HAP       1.00      1.00      1.00         3\n",
      "         HAS       0.98      0.98      0.98       357\n",
      "         IMP       0.25      0.50      0.33         2\n",
      "         INT       0.88      1.00      0.93        63\n",
      "         IST       0.94      0.90      0.92       499\n",
      "         ITJ       1.00      1.00      1.00         1\n",
      "         LES       1.00      1.00      1.00         4\n",
      "         LIT       0.80      0.87      0.83        23\n",
      "     MISSING       0.00      0.00      0.00         0\n",
      "         MOR       0.91      0.97      0.94        32\n",
      "         MOY       0.88      0.70      0.78        10\n",
      "         NEC       1.00      0.83      0.91        18\n",
      "         NIL       0.98      0.97      0.98      2096\n",
      "         NOT       0.98      0.99      0.99       188\n",
      "         NOW       0.97      0.99      0.98       711\n",
      "         NTH       0.00      0.00      0.00         5\n",
      "         ORD       0.83      0.71      0.77         7\n",
      "         ORG       0.83      0.48      0.61        31\n",
      "         PER       0.98      0.97      0.97       671\n",
      "         PFT       0.94      1.00      0.97        16\n",
      "         POS       1.00      1.00      1.00        23\n",
      "         PRG       1.00      0.75      0.86         4\n",
      "         PRO       1.00      0.98      0.99      1145\n",
      "         PRX       1.00      1.00      1.00        97\n",
      "         PST       0.98      0.98      0.98       262\n",
      "         QUC       0.93      0.87      0.90       212\n",
      "         QUE       1.00      1.00      1.00       312\n",
      "         QUV       0.98      0.95      0.97        59\n",
      "         REF       1.00      1.00      1.00         8\n",
      "         REL       0.98      0.97      0.98      1023\n",
      "         ROL       0.96      0.97      0.97       280\n",
      "         SCO       0.75      0.75      0.75         8\n",
      "         SUB       0.90      0.96      0.93        27\n",
      "         TOP       1.00      0.89      0.94        18\n",
      "         UOM       0.90      0.92      0.91       123\n",
      "         XCL       0.00      0.00      0.00         0\n",
      "         YOC       1.00      0.92      0.96        39\n",
      "\n",
      "    accuracy                           0.96     15388\n",
      "   macro avg       0.88      0.85      0.86     15388\n",
      "weighted avg       0.96      0.96      0.96     15388\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/.local/share/virtualenvs/semweb-ZPuVRBOP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/andre/.local/share/virtualenvs/semweb-ZPuVRBOP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/andre/.local/share/virtualenvs/semweb-ZPuVRBOP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/andre/.local/share/virtualenvs/semweb-ZPuVRBOP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/andre/.local/share/virtualenvs/semweb-ZPuVRBOP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/andre/.local/share/virtualenvs/semweb-ZPuVRBOP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test['semtag'].sum(), df_test['generated_tags'].sum()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('semweb-ZPuVRBOP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 19 2022, 17:35:49) [GCC 12.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ab5fffda9dff4a809b3cb5604230f92e198298742405aea7a03dc8ea956a946"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
