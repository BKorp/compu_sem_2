{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_fixer(df):\n",
    "    pred = []\n",
    "    gold = []\n",
    "    errors = []\n",
    "    for idx, row in df.iterrows():\n",
    "        if len(row.semtag) < len(row.gen_semtag):\n",
    "            pred += [i for i in row.gen_semtag[:len(row.semtag)]]\n",
    "            gold += [i for i in row.semtag]\n",
    "            errors.append([idx, 'longer', row.semtag, row.gen_semtag])\n",
    "        elif len(row.semtag) > len(row.gen_semtag):\n",
    "            errors.append([idx, 'shorter', row.semtag, row.gen_semtag])\n",
    "        else:\n",
    "            pred += [i for i in row.gen_semtag]\n",
    "            gold += [i for i in row.semtag]\n",
    "            \n",
    "    return gold, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_printer(in_file):\n",
    "    df = pd.read_json(in_file)\n",
    "\n",
    "    gold, pred = error_fixer(df)\n",
    "\n",
    "    print(classification_report(gold, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mt5_other_lang_classification(in_file):\n",
    "\n",
    "    df = pd.read_csv(in_file)\n",
    "\n",
    "    grouped_sentences = df.groupby('sent_file').agg({'token': list,\n",
    "                                                     'lemma': list,\n",
    "                                                     'from': list,\n",
    "                                                     'to': list,\n",
    "                                                     'semtag': list}).reset_index()\n",
    "\n",
    "    in_token = []\n",
    "    out_semtag = []\n",
    "    for index, data in grouped_sentences.iterrows():\n",
    "        cur_token = []\n",
    "        cur_semtag = []\n",
    "        cur_extra_id = -1\n",
    "        for word in data[1]:\n",
    "            cur_extra_id += 1\n",
    "            cur_token.append('<extra_id_{}> {} '.format(cur_extra_id, word))\n",
    "            cur_semtag.append('<extra_id_{}> {} '.format(cur_extra_id,\n",
    "                                                        data[-1][data[1].index(word)]))\n",
    "\n",
    "        in_token.append(cur_token)\n",
    "        out_semtag.append(cur_semtag)\n",
    "\n",
    "    grouped_sentences['in_token'] = in_token\n",
    "    grouped_sentences['out_semtag'] = out_semtag\n",
    "\n",
    "    return grouped_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_printer('./')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86d0237a3a54a747ea5eeadf5a7aab3e7ee246c76033eca4ace7d99a07ef554b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
