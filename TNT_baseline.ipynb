{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "psNs8XYNiug5"
      },
      "outputs": [],
      "source": [
        "from nltk.tag import tnt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pmb_data = pd.read_csv('sem-pmb_4_0_0-gold.csv')"
      ],
      "metadata": {
        "id": "JTDNeWdSmNyP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_extract(data):\n",
        "  '''Returns dataset in correct format for the NLTK TnT tagger tool'''\n",
        "  df = data.groupby(\"sent_file\")\n",
        "  column_val = []\n",
        "  for k, v in df:\n",
        "    column_val.append(v)\n",
        "\n",
        "  sentences = []\n",
        "  semtags = []\n",
        "  for n in column_val:\n",
        "    for x, y in n.items():\n",
        "      if x == 'token':\n",
        "        sentences.append(' '.join(map(str, y)))\n",
        "      elif x == 'semtag':\n",
        "        semtags.append(' '.join(map(str, y)))\n",
        "  return sentences, semtags\n",
        "\n",
        "def combine(sent, tags):\n",
        "  combined= []\n",
        "  sent = sent.split()\n",
        "  tags = tags.split()\n",
        "  for x, y in zip(sent, tags):\n",
        "    combined.append((''.join(x), ''.join(y)))\n",
        "  return combined\n",
        "\n",
        "sents, semtags = data_extract(pmb_data)\n",
        "data = []\n",
        "for x, y in zip(sents, semtags):\n",
        "  data.append(combine(x, y))"
      ],
      "metadata": {
        "id": "Q8q_ErC_mN6p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Splitting dataset into 80% train and 20% test'''\n",
        "train_data, test_data = train_test_split(data, test_size=0.20, random_state=1234)"
      ],
      "metadata": {
        "id": "iWxNtHBgPRNC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Setting up TnT tagger and training the train dataset'''\n",
        "tnt_tagger = tnt.TnT()\n",
        "tnt_tagger.train(train_data)"
      ],
      "metadata": {
        "id": "1xFuZT88i5OX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Calculating the accuracy score (calculated by built-in TnT function)'''\n",
        "acc = tnt_tagger.accuracy(test_data)\n",
        "print('Accuracy score on the test set: {}'.format(round(acc, 4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbcoSwO_jxp-",
        "outputId": "1d44ab31-9b75-4019-e990-15bce1bb678e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score on the test set: 0.8972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(test_set):\n",
        "  '''Returns predicted list with the sentences, where every sentence is split \n",
        "  pairs, consisting of the words and their predicted label tag'''\n",
        "  x = []\n",
        "  x_test = []\n",
        "  for sent in test_set:\n",
        "    for word_pair in sent:\n",
        "      x.append(word_pair[0])\n",
        "    x_test.append(' '.join(x))\n",
        "    x = []\n",
        "  \n",
        "  pred = []\n",
        "  for n in x_test:\n",
        "    n = n.split()\n",
        "    pred.append(tnt_tagger.tag(n))\n",
        "  return pred"
      ],
      "metadata": {
        "id": "OvxdSCrHxR8Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predict(test_data)"
      ],
      "metadata": {
        "id": "ClNKFWqi3TVa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Storing predicted and gold labels separtly'''\n",
        "label_pred = []\n",
        "label_gold = []\n",
        "for sent, pred in zip(test_data, predictions):\n",
        "  for s, p in zip(sent, pred):\n",
        "    label_gold.append(s[1])\n",
        "    label_pred.append(p[1])"
      ],
      "metadata": {
        "id": "6hxph-n136i3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(label_gold, label_pred, digits=4, zero_division=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf5z-bHP4x1n",
        "outputId": "52909947-7ba4-4dd4-ccf9-e1a8bb668b0b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ALT     0.9773    0.9149    0.9451        47\n",
            "         AND     0.9865    0.6952    0.8156       105\n",
            "         APX     1.0000    1.0000    1.0000        18\n",
            "         ART     1.0000    0.1818    0.3077        11\n",
            "         BOT     1.0000    1.0000    1.0000         2\n",
            "         BUT     1.0000    0.8421    0.9143        19\n",
            "         CLO     0.9615    0.6410    0.7692        39\n",
            "         COL     1.0000    1.0000    1.0000        27\n",
            "         CON     0.9763    0.8154    0.8886      1766\n",
            "         COO     0.8077    0.8077    0.8077        26\n",
            "         CTC     1.0000    0.2500    0.4000         4\n",
            "         DEF     0.9150    0.9819    0.9473      1601\n",
            "         DEG     0.8333    0.8333    0.8333        60\n",
            "         DIS     0.9596    0.8480    0.9003       980\n",
            "         DOM     0.4000    0.4000    0.4000        10\n",
            "         DOW     1.0000    1.0000    1.0000         5\n",
            "         DST     0.9623    1.0000    0.9808        51\n",
            "         EFS     1.0000    0.6250    0.7692         8\n",
            "         EMP     0.9333    0.9091    0.9211        77\n",
            "         ENS     0.8904    0.8309    0.8596       479\n",
            "         EPS     0.9352    0.8794    0.9064       738\n",
            "         EQU     1.0000    0.6522    0.7895        23\n",
            "         EXG     0.9659    0.7692    0.8564       221\n",
            "         EXS     0.8387    0.7751    0.8056       369\n",
            "         EXT     0.7273    0.5424    0.6214        59\n",
            "         FUT     1.0000    0.9231    0.9600        65\n",
            "         GEO     1.0000    0.3846    0.5556        26\n",
            "         GPE     0.9519    0.7333    0.8285       135\n",
            "         GPO     0.8276    0.6667    0.7385        36\n",
            "         GRE     1.0000    0.0000    0.0000         1\n",
            "         GRP     0.7000    0.8400    0.7636        25\n",
            "         HAP     1.0000    0.3333    0.5000         3\n",
            "         HAS     0.9728    0.9728    0.9728       367\n",
            "         IMP     1.0000    0.5000    0.6667         2\n",
            "         INT     0.9355    0.9206    0.9280        63\n",
            "         IST     0.9497    0.7575    0.8428       499\n",
            "         ITJ     1.0000    1.0000    1.0000         1\n",
            "         LES     1.0000    0.2500    0.4000         4\n",
            "         LIT     0.5714    0.1739    0.2667        23\n",
            "         MOR     0.9667    0.9062    0.9355        32\n",
            "         MOY     1.0000    1.0000    1.0000        10\n",
            "         NEC     0.8750    0.7778    0.8235        18\n",
            "         NIL     0.9952    0.9826    0.9889      2122\n",
            "         NOT     0.9947    0.9895    0.9921       190\n",
            "         NOW     0.9480    0.9480    0.9480       711\n",
            "         NTH     1.0000    0.0000    0.0000         5\n",
            "         ORD     1.0000    0.8750    0.9333         8\n",
            "         ORG     0.8182    0.2903    0.4286        31\n",
            "         PER     0.9964    0.8160    0.8972       674\n",
            "         PFT     0.9333    0.8750    0.9032        16\n",
            "         POS     1.0000    0.9583    0.9787        24\n",
            "         PRG     1.0000    0.7500    0.8571         4\n",
            "         PRO     0.9844    0.9896    0.9870      1150\n",
            "         PRX     1.0000    1.0000    1.0000       101\n",
            "         PST     0.9570    0.9351    0.9459       262\n",
            "         QUC     0.9667    0.8208    0.8878       212\n",
            "         QUE     0.9783    0.9906    0.9844       318\n",
            "         QUV     1.0000    0.9322    0.9649        59\n",
            "         REF     0.7000    0.8750    0.7778         8\n",
            "         REL     0.9750    0.9922    0.9835      1024\n",
            "         ROL     0.9821    0.7794    0.8690       281\n",
            "         SCO     1.0000    0.6250    0.7692         8\n",
            "         SUB     0.8065    0.9259    0.8621        27\n",
            "         TOP     1.0000    0.8889    0.9412        18\n",
            "         UOM     0.9832    0.9512    0.9669       123\n",
            "         Unk     0.0000    1.0000    0.0000         0\n",
            "         XCL     0.0000    1.0000    0.0000         0\n",
            "         YOC     1.0000    0.4872    0.6552        39\n",
            "\n",
            "    accuracy                         0.8972     15470\n",
            "   macro avg     0.9094    0.7649    0.7815     15470\n",
            "weighted avg     0.9582    0.8972    0.9232     15470\n",
            "\n"
          ]
        }
      ]
    }
  ]
}